{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Elasticsearch VectorDB & Information Retrieval\n",
    "\n",
    "This notebook demonstrates **advanced information retrieval techniques** using Elasticsearch, including:\n",
    "\n",
    "- **BM25**: The classic text-based retrieval algorithm\n",
    "- **Vector Search**: Semantic search using embeddings\n",
    "- **Hybrid Search**: Combining BM25 and vector search for best results\n",
    "- **Reranking**: Improving search results with cross-encoders\n",
    "- **Advanced Query Techniques**: Multi-match, boosting, filters, and more\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Make sure you have:\n",
    "- Elasticsearch running (local or cloud)\n",
    "- Required Python libraries installed\n",
    "- An API key if using Elasticsearch Cloud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Connection\n",
    "\n",
    "First, let's connect to Elasticsearch. You can use either:\n",
    "- **Local**: `http://localhost:9200` or `https://localhost:9200`\n",
    "- **Cloud**: Your Elasticsearch Cloud endpoint with an API key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Connection configuration\n",
    "ENDPOINT = \"https://localhost:9200\"  # Change to your endpoint\n",
    "API_KEY = \"TO_COMPLETE\"  # http://localhost:5601/app/management/security/api_keys/\n",
    "\n",
    "# Connect to Elasticsearch\n",
    "es = Elasticsearch(ENDPOINT, api_key=API_KEY, verify_certs=False)\n",
    "print(\"‚úÖ Connected to Elasticsearch\")\n",
    "print(f\"Cluster info: {es.info()['cluster_name']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Understanding BM25\n",
    "\n",
    "**BM25 (Best Matching 25)** is a ranking function used to estimate the relevance of documents to a given search query. It's the default text search algorithm in Elasticsearch.\n",
    "\n",
    "### Key Concepts:\n",
    "- **Term Frequency (TF)**: How often a term appears in a document\n",
    "- **Inverse Document Frequency (IDF)**: How rare/common a term is across all documents\n",
    "- **Field Length Normalization**: Adjusts for document length\n",
    "\n",
    "BM25 is excellent for:\n",
    "- Keyword matching\n",
    "- Exact phrase matching\n",
    "- Handling common vs. rare terms\n",
    "- Text-based search where semantic understanding isn't critical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1 Creating a Text-Only Index for BM25\n",
    "\n",
    "Let's create an index with text fields optimized for BM25 search:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample documents for our search experiments\n",
    "documents = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"title\": \"Introduction to Machine Learning\",\n",
    "        \"content\": \"Machine learning is a subset of artificial intelligence that enables systems to learn from data without explicit programming. It uses algorithms to identify patterns and make predictions.\",\n",
    "        \"category\": \"AI\",\n",
    "        \"views\": 1500\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"title\": \"Deep Learning Fundamentals\",\n",
    "        \"content\": \"Deep learning uses neural networks with multiple layers to process complex data. It's particularly effective for image recognition and natural language processing tasks.\",\n",
    "        \"category\": \"AI\",\n",
    "        \"views\": 2300\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"title\": \"Elasticsearch Search Engine\",\n",
    "        \"content\": \"Elasticsearch is a distributed search and analytics engine. It provides powerful full-text search capabilities using inverted indices and the BM25 ranking algorithm.\",\n",
    "        \"category\": \"Search\",\n",
    "        \"views\": 1800\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"title\": \"Vector Databases Explained\",\n",
    "        \"content\": \"Vector databases store high-dimensional vectors for similarity search. They're essential for semantic search, recommendation systems, and AI applications using embeddings.\",\n",
    "        \"category\": \"Database\",\n",
    "        \"views\": 2100\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"title\": \"Hybrid Search: Combining Text and Vectors\",\n",
    "        \"content\": \"Hybrid search combines traditional keyword search (BM25) with vector similarity search. This approach leverages both lexical matching and semantic understanding for better results.\",\n",
    "        \"category\": \"Search\",\n",
    "        \"views\": 950\n",
    "    },\n",
    "    {\n",
    "        \"id\": 6,\n",
    "        \"title\": \"Natural Language Processing Basics\",\n",
    "        \"content\": \"NLP enables computers to understand and process human language. Key techniques include tokenization, named entity recognition, and sentiment analysis.\",\n",
    "        \"category\": \"AI\",\n",
    "        \"views\": 1200\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create index for BM25 search\n",
    "index_name_bm25 = \"articles_bm25\"\n",
    "\n",
    "# Delete if exists\n",
    "if es.indices.exists(index=index_name_bm25):\n",
    "    es.indices.delete(index=index_name_bm25)\n",
    "    print(f\"üóëÔ∏è  Deleted existing index: {index_name_bm25}\")\n",
    "\n",
    "# Create index with text fields optimized for BM25\n",
    "es.indices.create(\n",
    "    index=index_name_bm25,\n",
    "    body={\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"title\": {\n",
    "                    \"type\": \"text\",\n",
    "                    \"analyzer\": \"standard\",  # Standard analyzer for BM25\n",
    "                    \"fields\": {\n",
    "                        \"keyword\": {\"type\": \"keyword\"}  # For exact matching\n",
    "                    }\n",
    "                },\n",
    "                \"content\": {\n",
    "                    \"type\": \"text\",\n",
    "                    \"analyzer\": \"standard\"\n",
    "                },\n",
    "                \"category\": {\"type\": \"keyword\"},\n",
    "                \"views\": {\"type\": \"integer\"}\n",
    "            }\n",
    "        },\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 0\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Index documents\n",
    "for doc in documents:\n",
    "    es.index(index=index_name_bm25, id=doc[\"id\"], document=doc)\n",
    "\n",
    "# Refresh to make documents searchable immediately\n",
    "es.indices.refresh(index=index_name_bm25)\n",
    "print(f\"‚úÖ Created index '{index_name_bm25}' and indexed {len(documents)} documents\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2 Basic BM25 Search\n",
    "\n",
    "Let's perform a simple BM25 search. Elasticsearch uses BM25 by default for text fields:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_search_results(response, query_text=\"\"):\n",
    "    \"\"\"Helper function to display search results nicely\"\"\"\n",
    "    print(f\"\\nüîç Search Results for: '{query_text}'\")\n",
    "    print(f\"Total hits: {response['hits']['total']['value']}\\n\")\n",
    "    \n",
    "    for i, hit in enumerate(response['hits']['hits'], 1):\n",
    "        score = hit['_score']\n",
    "        source = hit['_source']\n",
    "        print(f\"{i}. Score: {score:.4f}\")\n",
    "        print(f\"   Title: {source.get('title', 'N/A')}\")\n",
    "        print(f\"   Category: {source.get('category', 'N/A')}\")\n",
    "        print(f\"   Content preview: {source.get('content', '')[:100]}...\")\n",
    "        print()\n",
    "\n",
    "# Simple BM25 search\n",
    "query = \"machine learning\"\n",
    "response = es.search(\n",
    "    index=index_name_bm25,\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"content\": query\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "display_search_results(response, query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.3 Advanced BM25: Multi-Match and Boosting\n",
    "\n",
    "We can search across multiple fields and boost certain fields to give them more importance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-match query: search across multiple fields with boosting\n",
    "# Title matches are boosted 3x more than content matches\n",
    "query = \"search engine\"\n",
    "\n",
    "response = es.search(\n",
    "    index=index_name_bm25,\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": query,\n",
    "                \"fields\": [\"title^3\", \"content\"],  # ^3 means 3x boost\n",
    "                \"type\": \"best_fields\"  # Uses best matching field's score\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "display_search_results(response, query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.4 BM25 with Filters and Function Score\n",
    "\n",
    "We can combine BM25 with filters and custom scoring functions to create more sophisticated ranking strategies.\n",
    "\n",
    "#### Understanding Function Score\n",
    "\n",
    "The `function_score` query allows you to modify the relevance score of documents returned by a query. This is incredibly powerful for:\n",
    "- **Boosting popular content**: Increase scores for documents with high view counts, ratings, etc.\n",
    "- **Time-based ranking**: Boost recent content or decay older content\n",
    "- **Business logic**: Apply custom scoring based on any field value\n",
    "\n",
    "#### Key Components:\n",
    "\n",
    "1. **Base Query**: The BM25 query that finds matching documents\n",
    "2. **Filters**: Restrict results to specific criteria (faster than queries, cached)\n",
    "3. **Functions**: Mathematical transformations applied to field values\n",
    "4. **Boost Mode**: How to combine function scores with query scores\n",
    "\n",
    "#### Function Score Parameters Explained:\n",
    "\n",
    "- **`factor`**: Multiplier applied to the field value (e.g., 0.001 means divide by 1000)\n",
    "- **`modifier`**: Mathematical function to apply\n",
    "- **`boost_mode`**: How to combine function score with query score (sum, avg, etc.)\n",
    "\n",
    "#### Why Use Filters vs Queries?\n",
    "\n",
    "- **Filters** are faster because they:\n",
    "  - Don't calculate relevance scores\n",
    "  - Are cached automatically\n",
    "  - Use bit sets for efficient matching\n",
    "  - Perfect for exact matches (categories, tags, dates, etc.)\n",
    "\n",
    "- **Queries** calculate relevance scores and are better for:\n",
    "  - Text matching\n",
    "  - Fuzzy matching\n",
    "  - When you need scoring\n",
    "\n",
    "**Best Practice**: Use filters for exact matches, queries for relevance scoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine BM25 search with filters and boost by popularity (views)\n",
    "query = \"learning\"\n",
    "\n",
    "# Step-by-step explanation:\n",
    "# 1. Base query: Find documents matching \"learning\" in content (BM25 scoring)\n",
    "# 2. Filter: Only include documents where category = \"AI\" (no scoring, just filtering)\n",
    "# 3. Function: Calculate a boost based on the \"views\" field\n",
    "#    - factor: 0.001 means we're working with view counts divided by 1000\n",
    "#    - modifier: \"log1p\" applies log(1 + value) to smooth the effect\n",
    "#      This prevents documents with very high view counts from dominating\n",
    "# 4. boost_mode: \"sum\" adds the function score to the BM25 query score\n",
    "\n",
    "response = es.search(\n",
    "    index=index_name_bm25,\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"function_score\": {\n",
    "                \"query\": {\n",
    "                    \"bool\": {\n",
    "                        \"must\": [\n",
    "                            {\"match\": {\"content\": query}}  # BM25 text search\n",
    "                        ],\n",
    "                        \"filter\": [\n",
    "                            {\"term\": {\"category\": \"AI\"}}  # Filter: exact match, cached, no scoring\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                \"functions\": [\n",
    "                    {\n",
    "                        \"field_value_factor\": {\n",
    "                            \"field\": \"views\",\n",
    "                            \"factor\": 0.001,  # Divide views by 1000 (e.g., 1500 views ‚Üí 1.5)\n",
    "                            \"modifier\": \"log1p\"  # Apply log(1 + value) to smooth large differences\n",
    "                            # Example: log1p(1.5) ‚âà 0.916, log1p(2.3) ‚âà 1.178\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                \"boost_mode\": \"sum\"  # Final score = BM25_score + log1p(views * 0.001)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "display_search_results(response, f\"{query} (filtered: AI category, boosted by views)\")\n",
    "\n",
    "# Let's also show the scores breakdown for better understanding\n",
    "print(\"\\nüìä Score Breakdown:\")\n",
    "print(\"-\" * 80)\n",
    "for hit in response['hits']['hits']:\n",
    "    print(f\"Document: {hit['_source']['title']}\")\n",
    "    print(f\"  Final Score: {hit['_score']:.4f}\")\n",
    "    print(f\"  Views: {hit['_source']['views']}\")\n",
    "    print(f\"  Function contribution: log1p({hit['_source']['views']} * 0.001) ‚âà {np.log1p(hit['_source']['views'] * 0.001):.4f}\")\n",
    "    print(f\"  Estimated BM25 score: {hit['_score'] - np.log1p(hit['_source']['views'] * 0.001):.4f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Vector Search with Embeddings\n",
    "\n",
    "Vector search uses **embeddings** (dense vector representations) to find semantically similar documents, even if they don't share exact keywords.\n",
    "\n",
    "### Advantages:\n",
    "- **Semantic understanding**: Finds documents with similar meaning\n",
    "- **Multilingual**: Works across languages if embeddings are trained accordingly\n",
    "- **Context-aware**: Understands synonyms and related concepts\n",
    "\n",
    "### When to use:\n",
    "- Semantic similarity is more important than exact keyword matching\n",
    "- You need to find conceptually similar content\n",
    "- Working with multilingual content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1 Generating Embeddings\n",
    "\n",
    "We will now use a real embedding model (`sentence-transformers/all-MiniLM-L6-v2`) to convert text into 384-dimensional vectors. This model provides high-quality semantic embeddings that capture the meaning of text.\n",
    "\n",
    "**Setup**: To use the HuggingFace Inference API, you need to:\n",
    "1. Create an account on [Hugging Face](https://huggingface.co/)\n",
    "2. Generate a token at [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)\n",
    "3. Place your token in the `HF_TOKEN` variable below\n",
    "\n",
    "The model `all-MiniLM-L6-v2` produces 384-dimensional embeddings and is optimized for speed while maintaining good semantic understanding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFace Inference API setup\n",
    "MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "HF_TOKEN = \"TO_COMPLETE\"  # https://huggingface.co/settings/tokens\n",
    "\n",
    "import requests\n",
    "\n",
    "# API endpoint for feature extraction (embeddings)\n",
    "api_url = f\"https://router.huggingface.co/hf-inference/models/{MODEL_ID}/pipeline/feature-extraction\"\n",
    "headers = {\"Authorization\": f\"Bearer {HF_TOKEN}\"}\n",
    "\n",
    "def get_embedding(text: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Get embedding for a single text using HuggingFace Inference API.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text to embed\n",
    "        \n",
    "    Returns:\n",
    "        List of floats representing the 384-dimensional embedding vector\n",
    "    \"\"\"\n",
    "    response = requests.post(\n",
    "        api_url, \n",
    "        headers=headers, \n",
    "        json={\"inputs\": text, \"options\": {\"wait_for_model\": True}}\n",
    "    )\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Error from HuggingFace API: {response.status_code} - {response.text}\")\n",
    "    \n",
    "    # The API returns a list with one embedding vector\n",
    "    return response.json()[0]\n",
    "\n",
    "def get_embeddings_batch(texts: List[str]) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Get embeddings for multiple texts in a single API call (more efficient).\n",
    "    \n",
    "    Args:\n",
    "        texts: List of input texts to embed\n",
    "        \n",
    "    Returns:\n",
    "        List of embedding vectors (each is a list of floats)\n",
    "    \"\"\"\n",
    "    response = requests.post(\n",
    "        api_url,\n",
    "        headers=headers,\n",
    "        json={\"inputs\": texts, \"options\": {\"wait_for_model\": True}}\n",
    "    )\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Error from HuggingFace API: {response.status_code} - {response.text}\")\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "# Generate embeddings for our documents\n",
    "# all-MiniLM-L6-v2 produces 384-dimensional vectors\n",
    "embedding_dim = 384\n",
    "\n",
    "# Prepare texts for batch embedding (more efficient than individual calls)\n",
    "texts_to_embed = [f\"{doc['title']} {doc['content']}\" for doc in documents]\n",
    "\n",
    "# Get embeddings in batch\n",
    "print(\"üîÑ Generating embeddings using HuggingFace API...\")\n",
    "embeddings_batch = get_embeddings_batch(texts_to_embed)\n",
    "\n",
    "# Store embeddings in dictionary\n",
    "document_embeddings = {}\n",
    "for doc, embedding in zip(documents, embeddings_batch):\n",
    "    document_embeddings[doc['id']] = embedding\n",
    "\n",
    "print(f\"‚úÖ Generated {embedding_dim}-dimensional embeddings for {len(documents)} documents\")\n",
    "print(f\"Sample embedding (first 10 dims): {document_embeddings[1][:10]}\")\n",
    "print(f\"Embedding norm: {np.linalg.norm(document_embeddings[1]):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2 Creating a Vector Search Index\n",
    "\n",
    "Now let's create an index that supports vector similarity search:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index for vector search\n",
    "index_name_vector = \"articles_vector\"\n",
    "\n",
    "# Delete if exists\n",
    "if es.indices.exists(index=index_name_vector):\n",
    "    es.indices.delete(index=index_name_vector)\n",
    "    print(f\"üóëÔ∏è  Deleted existing index: {index_name_vector}\")\n",
    "\n",
    "# Create index with dense_vector field\n",
    "es.indices.create(\n",
    "    index=index_name_vector,\n",
    "    body={\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"title\": {\"type\": \"text\"},\n",
    "                \"content\": {\"type\": \"text\"},\n",
    "                \"category\": {\"type\": \"keyword\"},\n",
    "                \"views\": {\"type\": \"integer\"},\n",
    "                \"embedding\": {\n",
    "                    \"type\": \"dense_vector\",\n",
    "                    \"dims\": embedding_dim,\n",
    "                    \"index\": True,  # Enable approximate k-NN search\n",
    "                    \"similarity\": \"cosine\"  # Use cosine similarity\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 0\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Index documents with embeddings\n",
    "for doc in documents:\n",
    "    doc_with_embedding = doc.copy()\n",
    "    doc_with_embedding[\"embedding\"] = document_embeddings[doc[\"id\"]]\n",
    "    es.index(index=index_name_vector, id=doc[\"id\"], document=doc_with_embedding)\n",
    "\n",
    "# Refresh\n",
    "es.indices.refresh(index=index_name_vector)\n",
    "print(f\"‚úÖ Created vector index '{index_name_vector}' with {len(documents)} documents\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3 Vector Similarity Search\n",
    "\n",
    "Now let's perform a vector similarity search:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector similarity search\n",
    "query_text = \"artificial intelligence and neural networks\"\n",
    "query_embedding = get_embeddings_batch(query_text)\n",
    "\n",
    "response = es.search(\n",
    "    index=index_name_vector,\n",
    "    body={\n",
    "        \"knn\": {\n",
    "            \"field\": \"embedding\",\n",
    "            \"query_vector\": query_embedding,\n",
    "            \"k\": 5,\n",
    "            \"num_candidates\": 10  # Number of candidates to consider\n",
    "        },\n",
    "        \"_source\": [\"title\", \"content\", \"category\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "display_search_results(response, f\"Vector search: '{query_text}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Hybrid Search - The Best of Both Worlds\n",
    "\n",
    "**Hybrid search** combines BM25 (keyword matching) and vector search (semantic matching) to get the best results. This is one of the most powerful techniques in modern information retrieval.\n",
    "\n",
    "### Why Hybrid Search?\n",
    "- **BM25** excels at exact keyword matching and handling rare terms\n",
    "- **Vector search** excels at semantic understanding and finding conceptually similar content\n",
    "- **Combined**: You get both lexical and semantic relevance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.1 Creating a Hybrid Search Index\n",
    "\n",
    "We need an index that supports both text search (BM25) and vector search:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index for hybrid search\n",
    "index_name_hybrid = \"articles_hybrid\"\n",
    "\n",
    "# Delete if exists\n",
    "if es.indices.exists(index=index_name_hybrid):\n",
    "    es.indices.delete(index=index_name_hybrid)\n",
    "    print(f\"üóëÔ∏è  Deleted existing index: {index_name_hybrid}\")\n",
    "\n",
    "# Create index with both text and vector fields\n",
    "es.indices.create(\n",
    "    index=index_name_hybrid,\n",
    "    body={\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"title\": {\n",
    "                    \"type\": \"text\",\n",
    "                    \"analyzer\": \"standard\",\n",
    "                    \"fields\": {\n",
    "                        \"keyword\": {\"type\": \"keyword\"}\n",
    "                    }\n",
    "                },\n",
    "                \"content\": {\n",
    "                    \"type\": \"text\",\n",
    "                    \"analyzer\": \"standard\"\n",
    "                },\n",
    "                \"category\": {\"type\": \"keyword\"},\n",
    "                \"views\": {\"type\": \"integer\"},\n",
    "                \"embedding\": {\n",
    "                    \"type\": \"dense_vector\",\n",
    "                    \"dims\": embedding_dim,\n",
    "                    \"index\": True,\n",
    "                    \"similarity\": \"cosine\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 0\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Index documents with both text and embeddings\n",
    "for doc in documents:\n",
    "    doc_with_embedding = doc.copy()\n",
    "    doc_with_embedding[\"embedding\"] = document_embeddings[doc[\"id\"]]\n",
    "    es.index(index=index_name_hybrid, id=doc[\"id\"], document=doc_with_embedding)\n",
    "\n",
    "# Refresh\n",
    "es.indices.refresh(index=index_name_hybrid)\n",
    "print(f\"‚úÖ Created hybrid index '{index_name_hybrid}' with {len(documents)} documents\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.2 Advanced Hybrid Search with RRF (Reciprocal Rank Fusion)\n",
    "\n",
    "**Reciprocal Rank Fusion (RRF)** is a powerful technique to combine results from multiple retrieval methods. It's available in Elasticsearch 8.8+:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid search using RRF (Reciprocal Rank Fusion)\n",
    "# RRF combines results from multiple queries by fusing their rankings\n",
    "query_text = \"neural networks and deep learning\"\n",
    "query_embedding = get_embeddings_batch(query_text)\n",
    "\n",
    "# Note: RRF requires Elasticsearch 8.8+. If not available, use the previous method.\n",
    "try:\n",
    "    response = es.search(\n",
    "        index=index_name_hybrid,\n",
    "        body={\n",
    "            \"sub_searches\": [\n",
    "                {\n",
    "                    \"query\": {\n",
    "                        \"multi_match\": {\n",
    "                            \"query\": query_text,\n",
    "                            \"fields\": [\"title^3\", \"content\"]\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"knn\": {\n",
    "                        \"field\": \"embedding\",\n",
    "                        \"query_vector\": query_embedding,\n",
    "                        \"k\": 10,\n",
    "                        \"num_candidates\": 20\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            \"rank\": {\n",
    "                \"rrf\": {\n",
    "                    \"window_size\": 20,\n",
    "                    \"rank_constant\": 60\n",
    "                }\n",
    "            },\n",
    "            \"_source\": [\"title\", \"content\", \"category\"]\n",
    "        }\n",
    "    )\n",
    "    display_search_results(response, f\"RRF Hybrid search: '{query_text}'\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  RRF not available (requires ES 8.8+): {e}\")\n",
    "    print(\"Using alternative hybrid search method...\")\n",
    "    \n",
    "    # Fallback: manual hybrid search\n",
    "    response = es.search(\n",
    "        index=index_name_hybrid,\n",
    "        body={\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"should\": [\n",
    "                        {\"multi_match\": {\"query\": query_text, \"fields\": [\"title^3\", \"content\"]}},\n",
    "                        {\"match_all\": {}}\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"knn\": {\n",
    "                \"field\": \"embedding\",\n",
    "                \"query_vector\": query_embedding,\n",
    "                \"k\": 5,\n",
    "                \"num_candidates\": 10,\n",
    "                \"boost\": 0.5  # Weight for vector search\n",
    "            },\n",
    "            \"_source\": [\"title\", \"content\", \"category\"]\n",
    "        }\n",
    "    )\n",
    "    display_search_results(response, f\"Hybrid search (fallback): '{query_text}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part IV: Comparison: BM25 vs Vector vs Hybrid\n",
    "\n",
    "Let's compare the three approaches side by side:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison function\n",
    "def compare_search_methods(query_text: str):\n",
    "    \"\"\"Compare BM25, Vector, and Hybrid search for the same query\"\"\"\n",
    "    query_embedding = get_embeddings_batch(query_text)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"COMPARISON FOR QUERY: '{query_text}'\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 1. BM25 only\n",
    "    print(\"\\nüìù BM25 SEARCH (Keyword-based):\")\n",
    "    print(\"-\" * 80)\n",
    "    bm25_response = es.search(\n",
    "        index=index_name_bm25,\n",
    "        body={\n",
    "            \"query\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query_text,\n",
    "                    \"fields\": [\"title^3\", \"content\"]\n",
    "                }\n",
    "            },\n",
    "            \"size\": 3\n",
    "        }\n",
    "    )\n",
    "    for i, hit in enumerate(bm25_response['hits']['hits'], 1):\n",
    "        print(f\"  {i}. [{hit['_score']:.4f}] {hit['_source']['title']}\")\n",
    "    \n",
    "    # 2. Vector only\n",
    "    print(\"\\nüî¢ VECTOR SEARCH (Semantic):\")\n",
    "    print(\"-\" * 80)\n",
    "    vector_response = es.search(\n",
    "        index=index_name_vector,\n",
    "        body={\n",
    "            \"knn\": {\n",
    "                \"field\": \"embedding\",\n",
    "                \"query_vector\": query_embedding,\n",
    "                \"k\": 3,\n",
    "                \"num_candidates\": 10\n",
    "            },\n",
    "            \"size\": 3\n",
    "        }\n",
    "    )\n",
    "    for i, hit in enumerate(vector_response['hits']['hits'], 1):\n",
    "        print(f\"  {i}. [{hit['_score']:.4f}] {hit['_source']['title']}\")\n",
    "    \n",
    "    # 3. Hybrid\n",
    "    print(\"\\nüöÄ HYBRID SEARCH (BM25 + Vector):\")\n",
    "    print(\"-\" * 80)\n",
    "    hybrid_response = es.search(\n",
    "        index=index_name_hybrid,\n",
    "        body={\n",
    "            \"query\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query_text,\n",
    "                    \"fields\": [\"title^3\", \"content\"]\n",
    "                }\n",
    "            },\n",
    "            \"knn\": {\n",
    "                \"field\": \"embedding\",\n",
    "                \"query_vector\": query_embedding,\n",
    "                \"k\": 3,\n",
    "                \"num_candidates\": 10,\n",
    "                \"boost\": 0.5\n",
    "            },\n",
    "            \"size\": 3\n",
    "        }\n",
    "    )\n",
    "    for i, hit in enumerate(hybrid_response['hits']['hits'], 1):\n",
    "        print(f\"  {i}. [{hit['_score']:.4f}] {hit['_source']['title']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Test with different queries\n",
    "test_queries = [\n",
    "    \"machine learning\",\n",
    "    \"search engine technology\",\n",
    "    \"artificial intelligence\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    compare_search_methods(query)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part V: Advanced Query Techniques\n",
    "\n",
    "### V.1 Query Boosting and Negative Queries\n",
    "\n",
    "We can boost certain terms and exclude others:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced query with boosting and exclusions\n",
    "response = es.search(\n",
    "    index=index_name_bm25,\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": [\n",
    "                    {\"match\": {\"content\": \"learning\"}}\n",
    "                ],\n",
    "                \"should\": [\n",
    "                    {\"match\": {\"content\": {\"query\": \"neural\", \"boost\": 2.0}}},\n",
    "                    {\"match\": {\"content\": {\"query\": \"deep\", \"boost\": 1.5}}}\n",
    "                ],\n",
    "                \"must_not\": [\n",
    "                    {\"term\": {\"category\": \"Database\"}}  # Exclude Database category\n",
    "                ],\n",
    "                \"minimum_should_match\": 0\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "display_search_results(response, \"Advanced query: 'learning' (boosted: neural, deep; excluded: Database)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V.2 Phrase Matching and Proximity\n",
    "\n",
    "For exact phrase matching and controlling word proximity:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phrase matching: words must appear in exact order\n",
    "response = es.search(\n",
    "    index=index_name_bm25,\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"match_phrase\": {\n",
    "                \"content\": {\n",
    "                    \"query\": \"machine learning\",\n",
    "                    \"slop\": 2  # Allow up to 2 words between \"machine\" and \"learning\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "display_search_results(response, \"Phrase match: 'machine learning' (slop: 2)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V.3 Fuzzy Matching\n",
    "\n",
    "Fuzzy matching handles typos and spelling variations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuzzy matching: handles typos\n",
    "response = es.search(\n",
    "    index=index_name_bm25,\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"content\": {\n",
    "                    \"query\": \"machne lerning\",  # Intentional typos\n",
    "                    \"fuzziness\": \"AUTO\"  # Auto-detect fuzziness based on term length\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "display_search_results(response, \"Fuzzy match: 'machne lerning' (with typos)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part VI: Performance Optimization\n",
    "\n",
    "### VI.1 Index Settings for Performance\n",
    "\n",
    "Optimize index settings for better search performance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance-optimized index settings\n",
    "index_name_optimized = \"articles_optimized\"\n",
    "\n",
    "if es.indices.exists(index=index_name_optimized):\n",
    "    es.indices.delete(index=index_name_optimized)\n",
    "\n",
    "es.indices.create(\n",
    "    index=index_name_optimized,\n",
    "    body={\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 0,\n",
    "            \"refresh_interval\": \"30s\"\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"title\": {\"type\": \"text\"},\n",
    "                \"content\": {\"type\": \"text\"},\n",
    "                \"category\": {\"type\": \"keyword\"},\n",
    "                \"views\": {\"type\": \"integer\"},\n",
    "                \"embedding\": {\n",
    "                    \"type\": \"dense_vector\",\n",
    "                    \"dims\": embedding_dim,\n",
    "                    \"index\": True,\n",
    "                    \"similarity\": \"cosine\",\n",
    "                    \"index_options\": {\n",
    "                        \"type\": \"hnsw\",\n",
    "                        \"m\": 16,\n",
    "                        \"ef_construction\": 100\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Created optimized index with HNSW algorithm for faster vector search\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VI.2 Query Performance Tips\n",
    "\n",
    "Key tips for optimizing query performance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance tips demonstrated:\n",
    "\n",
    "# 1. Limit result size\n",
    "response = es.search(\n",
    "    index=index_name_bm25,\n",
    "    body={\n",
    "        \"query\": {\"match\": {\"content\": \"learning\"}},\n",
    "        \"size\": 5,  # Only return top 5 results\n",
    "        \"_source\": [\"title\", \"category\"]  # Only return needed fields\n",
    "    }\n",
    ")\n",
    "\n",
    "# 2. Use filters (faster than queries) when possible\n",
    "response = es.search(\n",
    "    index=index_name_bm25,\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": [\n",
    "                    {\"match\": {\"content\": \"learning\"}}\n",
    "                ],\n",
    "                \"filter\": [  # Filters are cached and faster\n",
    "                    {\"term\": {\"category\": \"AI\"}}\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        \"size\": 5\n",
    "    }\n",
    ")\n",
    "\n",
    "# 3. Use search_after for pagination (better than from/size for large datasets)\n",
    "response = es.search(\n",
    "    index=index_name_bm25,\n",
    "    body={\n",
    "        \"query\": {\"match_all\": {}},\n",
    "        \"size\": 2,\n",
    "        \"sort\": [{\"views\": \"desc\"}]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Performance optimization examples:\")\n",
    "print(\"   - Limited result size\")\n",
    "print(\"   - Used filters instead of queries where possible\")\n",
    "print(\"   - Used sorting for pagination\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part VIII: Best Practices and Recommendations\n",
    "\n",
    "### When to Use Each Method:\n",
    "\n",
    "1. **BM25 (Text Search)**\n",
    "   - ‚úÖ Exact keyword matching is important\n",
    "   - ‚úÖ You need to handle rare terms well\n",
    "   - ‚úÖ Working with structured text data\n",
    "   - ‚úÖ Fast, no embedding generation needed\n",
    "\n",
    "2. **Vector Search (Semantic Search)**\n",
    "   - ‚úÖ Semantic similarity is more important than exact matches\n",
    "   - ‚úÖ Multilingual content\n",
    "   - ‚úÖ Finding conceptually similar content\n",
    "   - ‚úÖ Working with embeddings from pre-trained models\n",
    "\n",
    "3. **Hybrid Search**\n",
    "   - ‚úÖ **Best for most production use cases**\n",
    "   - ‚úÖ Need both keyword and semantic matching\n",
    "   - ‚úÖ Want to maximize recall and precision\n",
    "   - ‚úÖ Have resources for both text and vector indexing\n",
    "\n",
    "### Performance Considerations:\n",
    "\n",
    "- **Index size**: Vector indices are larger than text indices\n",
    "- **Query latency**: Hybrid search is slower but more accurate\n",
    "- **Embedding generation**: Consider caching embeddings\n",
    "- **HNSW parameters**: Tune `m` and `ef_construction` based on your data size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook covered:\n",
    "\n",
    "‚úÖ **BM25**: Classic text-based retrieval with advanced query techniques  \n",
    "‚úÖ **Vector Search**: Semantic search using embeddings  \n",
    "‚úÖ **Hybrid Search**: Combining BM25 and vector search for optimal results  \n",
    "‚úÖ **Advanced Queries**: Boosting, filtering, phrase matching, fuzzy search  \n",
    "‚úÖ **Performance Optimization**: Index settings, query optimization  \n",
    "‚úÖ **Real-World System**: Complete search system implementation  \n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **BM25** is excellent for keyword matching and exact term retrieval\n",
    "2. **Vector search** excels at semantic understanding and finding similar concepts\n",
    "3. **Hybrid search** combines the best of both worlds and is recommended for production\n",
    "4. **Performance** can be optimized through proper index settings and query design\n",
    "5. **Real embedding models** should be used in production (not the demo function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)\n",
    "\n",
    "Uncomment the following cells to clean up the created indices:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete indices\n",
    "# indices_to_delete = [index_name_bm25, index_name_vector, index_name_hybrid, index_name_optimized]\n",
    "# \n",
    "# for index in indices_to_delete:\n",
    "#     if es.indices.exists(index=index):\n",
    "#         es.indices.delete(index=index)\n",
    "#         print(f\"üóëÔ∏è  Deleted index: {index}\")\n",
    "# \n",
    "# print(\"‚úÖ Cleanup complete\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
