{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fgAKN0lAR7d"
   },
   "source": [
    "# Tutorial : ElasticSearch & VectorDB\n",
    "\n",
    "# Elasticsearch and VectorDB tutorial\n",
    "\n",
    "This notebook aims to introduce the basic concepts of **Elasticsearch** as well as direct applications using **VectorDB**.\n",
    "\n",
    "Elasticsearch is an open-source project that you can install locally on your own machines. This has the advantage of not requiring an internet connection and keeping your data in an environment you control.  \n",
    "However, it is often more cost-effective to use a service provided by Elasticsearch to host such a database.\n",
    "\n",
    "For this tutorial, two options are available to run Elasticsearch and a data-visualization dashboard (Kibana):\n",
    "\n",
    " - **Option 1 (recommended)**: launch an Elasticsearch cluster with Kibana locally using the `.env` and `docker-compose.yml` files:\n",
    "\n",
    "```shell\n",
    "cd [this folder]\n",
    "docker compose up\n",
    "```\n",
    "(see if needed : https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html)\n",
    "\n",
    "- **Option 2**: use the Elasticsearch serverless trial version, which allows you to quickly get an Elasticsearch database connected to Kibana.\n",
    "To do this, simply go to https://cloud.elastic.co/registration\n",
    " and create an account. Once your account is created, you can create a deployment, which will give you an endpoint (e.g. https://10468406azdad...:443) as well as an API key.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E43hjpJbAR7f"
   },
   "source": [
    "Recommended setup:\n",
    "* This notebook uses some common libraries (`numpy`, `sklearn`, `plotly`, etc.) as well as less common ones (`elasticsearch`). It is recommended to use a virtual environment to run it via:\n",
    "\n",
    "```bash\n",
    "python3 -m venv venv\n",
    "source venv/bin/activate\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0qNPb9YUAR7h"
   },
   "outputs": [],
   "source": [
    "import urllib3\n",
    "# to disable certificate warnings\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from openTSNE import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-royI2GoAR7h"
   },
   "source": [
    "Whatever option you choose, the API key and the endpoint must be set in the `API_KEY` and `ENDPOINT` variables, respectively, to connect to your remote database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT = \"https://localhost:9200\"\n",
    "API_KEY = \"TO_COMPLETE\" # http://localhost:5601/app/management/security/api_keys/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ERLoDw84AR7i"
   },
   "outputs": [],
   "source": [
    "# connection test\n",
    "es = Elasticsearch(ENDPOINT, api_key=API_KEY, verify_certs=False)\n",
    "\n",
    "# API key should have cluster monitor rights\n",
    "es.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lG0tr6BnAR7j"
   },
   "source": [
    "## 1. What do we want to store in our database?\n",
    "\n",
    "VectorDBs allow storing vectors. These vectors are most often the results of a document *embedding* step performed before indexing in Elasticsearch.\n",
    "\n",
    "This *embedding* step is carried out by **dedicated models** (usually by extracting a layer from a deep neural network) and can be computationally expensive.\n",
    "\n",
    "Here, we will first define some functions that will allow us to work with vectors using the standard libraries dedicated to vector manipulation.\n",
    "\n",
    "As we saw earlier, certain algorithms are regularly used for indexing and similarity calculations of our documents.\n",
    "\n",
    "The framework we are using is as follows:\n",
    "* we want to index movies in order to **recommend** films that users might like\n",
    "* we have a list of movies associated with a **pre-calculated 3-dimensional embedding** produced by a model\n",
    "\n",
    "Note: in reality, embedding spaces are larger (e.g., 512 dimensions) to capture more information. In this lab, we will stick to 3 dimensions to make it easier to visualize the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNLu5lyiAR7j"
   },
   "source": [
    "### I.1 Dataset and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RdxWyLF7AR7k"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# our documents are stored in a dict\n",
    "movies = {\n",
    "    \"Inception\": np.array([0.12, 0.85, 0.34]),\n",
    "    \"Interstellar\": np.array([0.75, 4.0, 2.0]),\n",
    "    \"Black sheep\": np.array([-0.5, 0.5, -0.9]),\n",
    "    \"The Dark Knight\": np.array([0.90, 0.70, 0.10]),\n",
    "    \"La grande vadrouille\": np.array([-0.4, -0.87, 0.52]),\n",
    "    \"Sharknado 6\": np.array([-0.6, 0.3, -0.7]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JJPIin5AR7k"
   },
   "source": [
    "To understand the data we are working with, let's define a function to visualize our data in 3D.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "npUNf4vCAR7k"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_3d_vectors(vectors, labels=None, title=\"3D Vector Visualization\"):\n",
    "    \"\"\"\n",
    "        Visualizes 3D vectors with Plotly.\n",
    "\n",
    "        :param vectors: List or NumPy array of 3D vectors (shape Nx3).  \n",
    "        :param labels: List of labels for the vectors (optional).  \n",
    "        :param title: Title of the plot.\n",
    "    \"\"\"\n",
    "    if not isinstance(vectors, np.ndarray):\n",
    "        vectors = np.array(vectors)\n",
    "\n",
    "    if vectors.shape[1] != 3:\n",
    "        raise ValueError(\"Chaque vecteur doit avoir 3 dimensions.\")\n",
    "\n",
    "    # origin for each vector\n",
    "    origins = np.zeros_like(vectors)\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for i, vector in enumerate(vectors):\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[0,vector[0]], y=[0, vector[1]], z=[0, vector[2]],\n",
    "        ))\n",
    "\n",
    "        # Add labels if requested\n",
    "        if labels:\n",
    "            fig.add_trace(go.Scatter3d(\n",
    "                x=[vector[0]], y=[vector[1]], z=[vector[2]],\n",
    "                mode='text',\n",
    "                text=[labels[i]],\n",
    "                textposition='top center',\n",
    "                textfont=dict(color='red', size=12)\n",
    "            ))\n",
    "\n",
    "    # Axis conf\n",
    "    max_val = np.max(np.abs(vectors)) * 1.2\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis=dict(range=[-max_val, max_val], title=\"X\"),\n",
    "            yaxis=dict(range=[-max_val, max_val], title=\"Y\"),\n",
    "            zaxis=dict(range=[-max_val, max_val], title=\"Z\"),\n",
    "        ),\n",
    "        title=title,\n",
    "        margin=dict(l=0, r=0, b=0, t=50),\n",
    "    )\n",
    "\n",
    "    # plot\n",
    "    fig.show()\n",
    "\n",
    "movie_embeddings = np.array(list(movies.values()))\n",
    "movie_names = list(movies.keys())\n",
    "plot_3d_vectors(movie_embeddings, labels=movie_names, title=\"My top films\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBm9E7eOAR7l"
   },
   "source": [
    "### I.2 Definition of the most common Algorithms\n",
    "\n",
    "In this section, we define the most common algorithms and calculation methods used to estimate the similarity between two vectors:\n",
    "* cosine similarity\n",
    "* L2 norm\n",
    "* k-NN\n",
    "* hashing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J99PLejXAR7l"
   },
   "source": [
    "The cosine similarity is defined as $$\\cos(\\theta_{\\textbf{v,w}}) = \\frac{\\textbf{v} . \\textbf{w}}{\\Vert \\textbf{v}\\Vert_{2}\\Vert \\textbf{w}\\Vert_{2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nN-t73rsAR7l"
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_similarity(vector_1, vector_2):\n",
    "    return np.dot(vector_1, vector_2) / (norm(vector_1) * norm(vector_2))\n",
    "\n",
    "# computation of the cosine similarity with a vector we query\n",
    "query_vector = movies[\"Inception\"]\n",
    "# query_vector = np.array([0.47, -0.53, 0.95])\n",
    "for movie_name, movie_embedding in zip(movie_names, movie_embeddings):\n",
    "    cosine_results = cosine_similarity(query_vector, movie_embedding)\n",
    "    print(f\"Cosine Similarity with {movie_name}:\", cosine_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4E8ujUjhAR7l"
   },
   "source": [
    "*(Optional): How can we vectorize the calculation of cosine similarity?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZyTmP3YAR7l"
   },
   "source": [
    "#### k-NN: k-Nearest Neighbours\n",
    "\n",
    "The goal is to retrieve the k nearest neighbors using the L2 norm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hOM3kAT4AR7m"
   },
   "outputs": [],
   "source": [
    "def knn(query_embedding, embeddings, k=2, labels=None):\n",
    "    \"\"\"\n",
    "    `query_embedding` is the vector being queried  \n",
    "    Args:  \n",
    "        query_embedding (np.ndarray): vector to query  \n",
    "        embeddings (np.ndarray): vectors already in the database (shape (n,3))  \n",
    "        k (int, optional): number of neighbors. Defaults to 2.  \n",
    "    \n",
    "    Returns:  \n",
    "        List: k nearest neighbors sorted by distance\n",
    "    \n",
    "    \"\"\"\n",
    "    if labels is None:\n",
    "        labels = [\"\"] * embeddings.shape[0]\n",
    "\n",
    "    distances = []\n",
    "    for embedding, title in zip(embeddings, labels):\n",
    "        dist = np.linalg.norm(embedding - query_embedding)  # euclidean distance\n",
    "        distances.append((title, dist))\n",
    "    # sort by increasing distance and select the k nearest neighbours\n",
    "    return sorted(distances, key=lambda x: x[1])[:k]\n",
    "\n",
    "# find the 2 closest films\n",
    "nearest_neighbors = knn(query_vector, movie_embeddings, k=2, labels=movie_names)\n",
    "print(\"k-NN Results:\", nearest_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuXiKN6YAR7m"
   },
   "source": [
    "#### Locality Sensitive Hashing\n",
    "\n",
    "When working with embeddings in high (or very high) dimensions, it can be useful to **represent them in a smaller space**.\n",
    "\n",
    "The idea of LSH is to **assign similar hashes with high probability** to nearby embeddings.\n",
    "\n",
    "To do this, we generate $k$ random hyperplanes and, for each vector in our database, we check on which side of each hyperplane it lies (positive or negative). This defines a hash composed of 1s and 0s.\n",
    "\n",
    "Concretely, a hyperplane is defined by a normal vector $\\textbf{n}$:  \n",
    "$$H = \\{\\textbf{x} \\in \\mathbb{R}^d, \\textbf{x} \\cdot \\textbf{n} = 0\\}$$\n",
    "\n",
    "Thus, for the $k$-th hyperplane defined by the normal vector $\\textbf{n}_k$, if $\\textbf{x} \\cdot \\textbf{n}_k \\geq 0$, we assign the value 1 to the $k$-th coordinate of the hash vector, and 0 otherwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ma3DHpcFAR7m"
   },
   "outputs": [],
   "source": [
    "random_hyperplanes_vectors = np.random.rand(3, 8) * 2 - 1\n",
    "random_vectors = np.random.rand(10,3)\n",
    "\n",
    "def get_embedding(vector, hyperplanes_vectors):\n",
    "    dot_product = vector@hyperplanes_vectors\n",
    "    return (dot_product >= 0).astype(int)\n",
    "\n",
    "for vector, movie_name in zip(movie_embeddings, movie_names):\n",
    "    print(movie_name, get_embedding(vector, random_hyperplanes_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0gZJ44ZWAR7m"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "class LocalitySensitiveHashing:\n",
    "    def __init__(self, num_hashes=10, dimensions=100):\n",
    "        \"\"\"\n",
    "        Initializes the LSH algorithm.\n",
    "\n",
    "        :param num_hashes: Number of hash functions to use.\n",
    "        :param dimensions: Dimensions of the input vectors.\n",
    "        \"\"\"\n",
    "\n",
    "        self.num_hashes = num_hashes\n",
    "        self.dimensions = dimensions\n",
    "        # generates random hyperplanes for the hash functions\n",
    "        self.hash_planes = (np.random.rand(num_hashes, dimensions) * 2) - 1\n",
    "        self.hash_tables = defaultdict(list)\n",
    "\n",
    "    def hash_vector(self, vector):\n",
    "        \"\"\"\n",
    "        Hashes a given vector according to the generated hyperplanes.\n",
    "\n",
    "        :param vector: Input vector (numpy array).\n",
    "        :return: A tuple representing the binary signature of the vector.\n",
    "        \"\"\"\n",
    "\n",
    "        return tuple(\n",
    "            (np.dot(vector, plane) >= 0).astype(int) for plane in self.hash_planes\n",
    "        )\n",
    "\n",
    "    def add_vector(self, vector, label):\n",
    "        \"\"\"\n",
    "        Adds a vector to the hash tables.\n",
    "\n",
    "        :param vector: Vector to index.\n",
    "        :param label: Identifier or label associated with the vector.\n",
    "        \"\"\"\n",
    "\n",
    "        hash_key = self.hash_vector(vector)\n",
    "        self.hash_tables[hash_key].append(label)\n",
    "\n",
    "    def query(self, vector):\n",
    "        \"\"\"\n",
    "        Searches for approximate neighbors for a given vector.\n",
    "\n",
    "        :param vector: Vector to search for.\n",
    "        :return: List of labels associated with potential neighbors.\n",
    "        \"\"\"\n",
    "\n",
    "        hash_key = self.hash_vector(vector)\n",
    "        return self.hash_tables[hash_key]\n",
    "\n",
    "\n",
    "# Creates a LSH instance\n",
    "lsh = LocalitySensitiveHashing(num_hashes=5, dimensions=3)\n",
    "\n",
    "# add vectors with labels\n",
    "vectors = {\n",
    "    \"A\": np.array([1, 2, 3]),\n",
    "    \"B\": np.array([4, 5, 6]),\n",
    "    \"C\": np.array([-1, -2, -1]),\n",
    "    \"D\": np.array([5, 5, 5]),\n",
    "}\n",
    "\n",
    "for label, vector in vectors.items():\n",
    "    lsh.add_vector(vector, label)\n",
    "\n",
    "# look for approximate nearest neighbours\n",
    "query_vector = np.array([1, 1, 1])\n",
    "neighbors = lsh.query(query_vector)\n",
    "print(f\"Neighbors of {query_vector}: {neighbors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c18rSxRnAR7n"
   },
   "source": [
    "## II. Indexing in Elasticsearch\n",
    "\n",
    "After reviewing the classic algorithms used for similarity calculation and document indexing, we can now see how to use them in practice with Elasticsearch.\n",
    "\n",
    "First, we need to create an index that will store our documents. This index will contain the movie titles as well as the associated embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6pBYv7rAR7n"
   },
   "source": [
    "### II.1 Index with euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zsQP7rBwAR7n"
   },
   "outputs": [],
   "source": [
    "# creation of an index\n",
    "index_name = \"movies\"\n",
    "es.options(ignore_status=400).indices.create(\n",
    "    index=index_name,\n",
    "    body={\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"title\": {\"type\": \"text\"},\n",
    "                \"vector\": {\n",
    "                    \"type\": \"dense_vector\",\n",
    "                    \"dims\": 3,\n",
    "                    \"index\": True,\n",
    "                    \"similarity\": \"l2_norm\",\n",
    "                },  # index is set to True to allow the use of knn search queries\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "for title, vector in movies.items():\n",
    "    es.index(index=index_name, document={\"title\": title, \"vector\": vector.tolist()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzy8ABThAR7n"
   },
   "source": [
    "You can verify that the index has been successfully created by going to the Kibana interface, navigating to `Stack Management` at the bottom of the left sidebar, and then to `Data => Index Management`.\n",
    "\n",
    "Our index should be visible and contain our documents corresponding to the movies.\n",
    "\n",
    "**Objective:** Given a vector corresponding to a movie that a user liked, how can we find, via an Elasticsearch query, the closest movie in terms of Euclidean distance in the embedding space?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwp9WjgEAR7n"
   },
   "outputs": [],
   "source": [
    "# query definition\n",
    "query = {\n",
    "    \"knn\": {\n",
    "        \"field\": \"vector\",\n",
    "        \"query_vector\": query_vector.tolist(),\n",
    "        \"k\": 3,\n",
    "        \"num_candidates\": 3,\n",
    "    },\n",
    "    \"_source\": [\"title\"],\n",
    "}\n",
    "\n",
    "response = es.search(index=index_name, body=query)\n",
    "print(\"Elasticsearch k-NN Results:\", response[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1iI1ftyGAR7o"
   },
   "outputs": [],
   "source": [
    "def display_nearest_neighbors(results):\n",
    "    print(\"\\nüîç **Closest neighbours** üîç\\n\")\n",
    "    for i, result in enumerate(results, start=1):\n",
    "        title = result['_source'].get('title', 'Titre inconnu')\n",
    "        score = result.get('_score', 0)\n",
    "        index = result.get('_index', 'Index inconnu')\n",
    "        doc_id = result.get('_id', 'ID inconnu')\n",
    "\n",
    "        print(f\"üé¨ **Neighbour {i}**\")\n",
    "        print(f\"   üìÅ Index : {index}\")\n",
    "        print(f\"   üìú ID Document : {doc_id}\")\n",
    "        print(f\"   üìå Title : {title}\")\n",
    "        print(f\"   ‚≠ê Similarity score : {score:.6f}\\n\")\n",
    "\n",
    "display_nearest_neighbors(response[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6r6NxKPAR7o"
   },
   "source": [
    "### II.2 Index with Cosine Similarity\n",
    "\n",
    "In the previous section, we did not specify that we wanted to use Euclidean distance to determine similarity between vectors; this is the default behavior (see the documentation here: https://www.elastic.co/guide/en/elasticsearch/reference/current/dense-vector.html#dense-vector-similarity).\n",
    "\n",
    "Now, we want to retrieve the previous results using, for example, cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tWRjlC1LAR7o"
   },
   "outputs": [],
   "source": [
    "# creation of an index\n",
    "index_name = \"movies_cosine\"\n",
    "es.options(ignore_status=400).indices.create(\n",
    "    index=index_name,\n",
    "    body={\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"title\": {\"type\": \"text\"},\n",
    "                \"vector\": {\n",
    "                    \"type\": \"dense_vector\",\n",
    "                    \"dims\": 3,\n",
    "                    \"index\": True,\n",
    "                    \"similarity\": \"cosine\",\n",
    "                },  # index is set to True to allow the use of knn search queries\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "for title, vector in movies.items():\n",
    "    es.index(index=index_name, document={\"title\": title, \"vector\": vector.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5nUaUgo3AR7o"
   },
   "outputs": [],
   "source": [
    "# NN using cosine similarity\n",
    "query = {\n",
    "    \"knn\": {\n",
    "        \"field\": \"vector\",\n",
    "        \"query_vector\": query_vector.tolist(),\n",
    "        \"k\": 3,\n",
    "        \"num_candidates\": 3,\n",
    "    },\n",
    "    \"_source\": [\"title\"],\n",
    "}\n",
    "\n",
    "response = es.search(index=index_name, body=query)\n",
    "display_nearest_neighbors(response[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "leLhR71vAR7o"
   },
   "outputs": [],
   "source": [
    "plot_3d_vectors(np.concatenate([movie_embeddings, query_vector[None, :]]), labels=movie_names + [\"query_vector\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKRyB6GxAR7p"
   },
   "source": [
    "The results are not the same! Depending on the similarity calculation method, the returned documents differ, so it is important to know the embedding model used initially to create our database.\n",
    "\n",
    "Here, the embeddings of the movies `Inception` and `Interstellar` are very close in terms of cosine similarity but far apart in Euclidean distance. It may be appropriate to complement our embedding step with a normalization step of the embeddings before insertion.\n",
    "\n",
    "The similarity measures used by Elasticsearch : https://www.elastic.co/guide/en/elasticsearch/reference/current/dense-vector.html#dense-vector-similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Me7bvVsAR7p"
   },
   "source": [
    "## III. And in reality...\n",
    "\n",
    "We will now use a real embedding model (here, all-MiniLM-L6-v2) to convert sentences into 384-dimensional vectors, which we will then insert into Elasticsearch.  \n",
    "To do this, you will need to create an account on Hugging Face (https://huggingface.co/) and then generate a token (https://huggingface.co/) which you will place in the \"HF_TOKEN\" field.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mfat98zpAR7p"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "HF_TOKEN = \"TO_COMPLETE\" # https://huggingface.co/settings/tokens\n",
    "\n",
    "import requests\n",
    "\n",
    "api_url = f\"https://router.huggingface.co/hf-inference/models/{MODEL_ID}/pipeline/feature-extraction\"\n",
    "headers = {\"Authorization\": f\"Bearer {HF_TOKEN}\"}\n",
    "\n",
    "def query(texts):\n",
    "    response = requests.post(api_url, headers=headers, json={\"inputs\": texts, \"options\":{\"wait_for_model\":True}})\n",
    "\n",
    "    return response.json()\n",
    "\n",
    "texts = [\"How do I get a replacement Medicare card?\",\n",
    "         \"What is the monthly premium for Medicare Part B?\",\n",
    "         \"How do I terminate my Medicare Part B (medical insurance)?\",\n",
    "         \"How do I sign up for Medicare?\",\n",
    "         \"Can I sign up for Medicare Part B if I am working and have health insurance through an employer?\",\n",
    "         \"How do I sign up for Medicare Part B if I already have Part A?\",\n",
    "         \"What are Medicare late enrollment penalties?\",\n",
    "         \"What is Medicare and who can get it?\",\n",
    "         \"How can I get help with my Medicare Part A and Part B premiums?\",\n",
    "         \"What are the different parts of Medicare?\",\n",
    "         \"Will my Medicare premiums be higher because of my higher income?\",\n",
    "         \"What is TRICARE ?\",\n",
    "         \"Should I sign up for Medicare Part B if I have Veterans' Benefits?\"]\n",
    "\n",
    "output = query(texts)\n",
    "\n",
    "nb_dim = len(output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6A8jZqHOAR7p"
   },
   "source": [
    "We have obtained the vectors for the sentences using the embedding model. We can now insert them into Elasticsearch in a new index called \"sentences\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SHR3RmErAR7p"
   },
   "outputs": [],
   "source": [
    "# creation of an index\n",
    "sentences = {sentence: vectors for sentence, vectors in zip(texts, output)}\n",
    "\n",
    "index_name = \"sentences\"\n",
    "es.options(ignore_status=400).indices.create(\n",
    "    index=index_name,\n",
    "    body={\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"title\": {\"type\": \"text\"},\n",
    "                \"vector\": {\n",
    "                    \"type\": \"dense_vector\",\n",
    "                    \"dims\": nb_dim,\n",
    "                    \"index\": True,\n",
    "                    \"similarity\": \"cosine\",\n",
    "                },  # index is set to True to allow the use of knn search queries\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Indexation des documents\n",
    "for title, vector in sentences.items():\n",
    "    es.index(index=index_name, document={\"title\": title, \"vector\": vector})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_51ntZeAR7p"
   },
   "source": [
    "We can now write a \"query\" message, which, once converted into a vector, allows us to find the sentences that are semantically closest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rsaxd6Y4AR7q"
   },
   "outputs": [],
   "source": [
    "# Recherche par similarit√© vectorielle\n",
    "request = [\"I am a veteran, how can I proceed to signup?\"]\n",
    "embedded_request = query(request)[0]\n",
    "\n",
    "es_query = {\n",
    "    \"knn\": {\n",
    "        \"field\": \"vector\",\n",
    "        \"query_vector\": embedded_request,\n",
    "        \"k\": 3,\n",
    "        \"num_candidates\": 3,\n",
    "    },\n",
    "    \"_source\": [\"title\"],\n",
    "}\n",
    "\n",
    "response = es.search(index=index_name, body=es_query)\n",
    "display_nearest_neighbors(response[\"hits\"][\"hits\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFZh3xD6AR7q"
   },
   "source": [
    "### 3D Visualization\n",
    "\n",
    "It is possible to visualize high-dimensional vectors (here, 384 dimensions) in a way that humans can understand, provided they are reduced to 2 or 3 dimensions using a dimensionality reduction algorithm.\n",
    "\n",
    "The T-SNE algorithm is a non-linear dimensionality reduction method that allows reducing from 384 to 3 dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "05oK8AIHAR72"
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=3)\n",
    "sentence_emb_3d = tsne.fit(np.concatenate([np.array(output), np.array([embedded_request])]))\n",
    "sentence_emb_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8WDME04mAR72"
   },
   "outputs": [],
   "source": [
    "plot_3d_vectors(sentence_emb_3d, labels=texts + [f\"REQUEST: {request[0]}\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vcXfgeoeAR72"
   },
   "source": [
    "IV - Additional exercises :\n",
    "\n",
    "1) Design your own neural network to embed MNIST images in a smaller space.\n",
    "- What could be a good basic architecture for this?\n",
    "- Use pytorch to implement it.\n",
    "- Test your implementation by fiddling around with your data\n",
    "\n",
    "2) To illustrate the reason graphs can be a nice tool to find nearest neighbours, use a Delaunay triangulation to find nearest neighbours in 2D space.\n",
    "- Design an experience with 100 000 random 2D vectors\n",
    "- Discover what a Delaunay triangulation is (understanding how it is related to a Vorono√Ø diagram may help you)\n",
    "- Compute a Delaunay triangulation on your random vectors\n",
    "- Generate a new 2D point which we will use as a query\n",
    "- Use either a spatial index or a walking algorithm to find the triangle containing this point\n",
    "- Find the nearest neighbour in the triangle\n",
    "- You can implement a BFS algorithm to request the k nearest neighbours\n",
    "\n",
    "Of course, here it is exact but it should give you an overview of how graph-based ANNs work in practice.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
